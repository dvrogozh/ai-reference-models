fp16-batch-inference:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-segmentation-pytorch-flex-gpu-unetpp-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  env:
    PRECISION: fp16
    BATCH_SIZE: '8'
    PLATFORM: 'Flex'
    MULTI_TILE: 'False'
    OUTPUT_DIR: /tmp
  volumes:
    - src: /tmp
      dst: /tmp
